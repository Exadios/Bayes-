BayesFilter TODO List

FOR RELEASE
		Build GCC2.95.3 and VC7
	Check what UBLAS macros are needed
		For exceptions/errors
		For storage
		Run with sparse
		Run Simple, PV, QuadCalib

TODO
	Document state virtual bases. Important that init and update protocols are used
	unit test rcond_ignore_infinity_internal . rcond!=rcond was changed. Still OK?
	Document numeric postcondition

	By products: add observe parameterisation for by products and temps
		observe innovation, surely it is something that is always computable by all schemes
			This should be the first "by_product"
	Use f() to represent normal models parametised at state x
		Rejected current model are parameterised as state
	Extended update managment helper
	Replace General_ with a form that works with functional forms
	Replace UdU function with UdU class

	UD_filter
		observeUD : return 0 for semi-definate (or zero)

NEW FILTERS
	Factorised UKF or DDF2
	VSDF (factorised from) from Matt Deans
	SIR with Auxilary variables
	Sparse matrix implementations: Requires sparse UdU. Great care of ublas sparse_matrix as it is row/column major
	 This make a big difference to speed. Hard for prod(L,R) need to have oposite orienation

TO REVIEW
	Sharing state in filters: Provided constructors with state references
	Check consistency of model to filter
		Validate (z to h.Z) model sizes in predict and observe
	UDpredict catching Negative matrices in observe
	Check normalisation: Standard form should be to normalise z. It is nice to have zp consistent with itself i.e. Hx
	Check when numerics fail for both state and obs semidefinate

ISSUES
	Enable Cov and Inf implmentations for PSD matricies where numerically possible. At present may be PD only

CODE RULES
	filter
		copy assigment, optimised to remove temps
	predict/observe
		in BayesFlt.h	must be virtual. The types are polymorphic
		in xxFlt.h		no vitual. These are specialised forms
	filter_matrix
		use Vec/Matrix x.assign (prod(a,b)); avoiding copy overhead

TESTING
	Unscented_filter
		for q_size > x_size  Don´t forget more noise is injected into nonlinear model => different observe result!

DOCUMENTATION
	Describe generic schemes
	Why Gq noise model. It is always non signular. Important for any numerics
		Q may have zeros. But if we have G then linear algebra can still use inverse.
		This is also why inverse(G) is not needed in inverse model. It would not be defined for signular Q



// Hmmm this seems to be not the best algorithm numerically
// The good one from A+G uses element multiples
template<class M>
bool compact_cholesky (M &m)
{
	using namespace ublas;
	bool negative = false;
	size_t size = m.size1();
	for (size_t i = 0; i < size; ++ i)
	{
		typename M::value_type t (m (i, i));
		vector_range<matrix_column<M> > v(project(column(m,i), range(i+1,size)));
		v -=
			prod(project (m, range (i + 1, size), range (0, i)),
			conj (project (row (m, i),range (0, i))));
		t -= inner_prod (conj (project (row(m, i), range (0,i))),project (row (m, i),range (0, i)));
		if (t <= 0)  {
			negative = true;
			break;
		};
		t = std::sqrt (t);
		m (i, i) = t;
		v /= t;
	}
	return negative;
}

UTriMatrix::value_type UCfactor (UTriMatrix& M, size_t n)
{
	assert (M.size1() == n);
	assert (M.size2() == n);
	bool negative = lower_cholesky(M);
	// Estimate the reciprocal condition number
	if (negative)
		return -1;
	return UCrcond (M,n);
}

